{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_extraction(sig, rate, nfft=2048, **kwargs):\n",
    "    \"\"\"Compute mean and standard deviation of each MFCCs from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the samplerate of the signal we are working with.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param numcep: the number of cepstrum to return, default 13\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 2048.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n",
    "    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: Two numpy arrays of size (numcep,). First vector contains mean of MFCCs, second - standard deviation of MFCCs\n",
    "    \"\"\"\n",
    "    mfcc_feat = mfcc(sig, rate, nfft=nfft, **kwargs)\n",
    "    mfcc_mean = mfcc_feat.mean(axis=0)\n",
    "    mfcc_std = mfcc_feat.std(axis=0)\n",
    "    return mfcc_mean, mfcc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = './datasets/toronto/'\n",
    "\n",
    "categorie_folders = [name for name in os.listdir(DATASET) if os.path.isdir(DATASET+name)]\n",
    "categories = {}\n",
    "category_N = 0\n",
    "for category in categorie_folders:\n",
    "    categories[category_N] = category\n",
    "    category_N += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.zeros((0, 27))\n",
    "for category_N, category in categories.items():\n",
    "    waves = [f for f in os.listdir(DATASET+category) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        try:\n",
    "            rate, sig = wavfile.read(DATASET+category + '/' + wav)\n",
    "        except ValueError:\n",
    "            print('ValueError: '+DATASET+category + '/' + wav)\n",
    "            continue\n",
    "        mfcc_mean, mfcc_std = features_extraction(sig, rate)\n",
    "        features = np.concatenate((mfcc_mean, mfcc_std, [category_N])).reshape(1,27)\n",
    "        dataset = np.concatenate((dataset, features))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = './datasets/ravdess/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for category_N, category in categories.items():\n",
    "    waves = [f for f in os.listdir(DATASET+category) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        try:\n",
    "            rate, sig = wavfile.read(DATASET+category + '/' + wav)\n",
    "        except ValueError:\n",
    "            print('ValueError: '+DATASET+category + '/' + wav)\n",
    "            continue\n",
    "        mfcc_mean, mfcc_std = features_extraction(sig, rate)\n",
    "        features = np.concatenate((mfcc_mean, mfcc_std, [category_N])).reshape(1,27)\n",
    "        dataset = np.concatenate((dataset, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4048, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Angry',\n",
       " 1: 'Disgust',\n",
       " 2: 'Fear',\n",
       " 3: 'Happy',\n",
       " 4: 'Neutral',\n",
       " 5: 'Pleasant Surprise',\n",
       " 6: 'Sad'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"dataset_toronto+ravdess(without calm).csv\", dataset, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_ravdess_train = np.zeros((0, 27))\n",
    "dataset_ravdess_test = np.zeros((0, 27))\n",
    "np.random.shuffle(dataset)\n",
    "dataset_train_len = int(dataset.shape[0] * 0.7)\n",
    "dataset_ravdess_train = np.concatenate((dataset_ravdess_train, dataset[:dataset_train_len]))\n",
    "dataset_ravdess_test = np.concatenate((dataset_ravdess_test, dataset[dataset_train_len:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train_X = dataset_ravdess_train[:,:-1]\n",
    "dataset_train_Y = dataset_ravdess_train[:,-1]\n",
    "dataset_test_X = dataset_ravdess_test[:,:-1]\n",
    "dataset_test_Y = dataset_ravdess_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly', degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2833, 26)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(dataset_train_X, dataset_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_predict_Y = clf.predict(dataset_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83045267489711938"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(dataset_test_X, dataset_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(dataset_test_Y, dataset_predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[187,   5,   2,   1,   2,   4,   1],\n",
       "       [  9, 136,   2,   5,   3,   7,   3],\n",
       "       [  4,   2, 140,  10,   1,   4,  12],\n",
       "       [  5,   4,  11, 140,   2,  10,   1],\n",
       "       [  1,   5,   2,   2, 130,   0,   8],\n",
       "       [  9,  10,   6,  10,   7, 133,   1],\n",
       "       [  3,   4,   9,   4,  13,   2, 143]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925742574257\n",
      "0.824242424242\n",
      "0.809248554913\n",
      "0.809248554913\n",
      "0.878378378378\n",
      "0.755681818182\n",
      "0.803370786517\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(c_matrix[i,i]/c_matrix[i].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
